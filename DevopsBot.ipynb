{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0684f7-dc98-4c9d-bdef-db3219000b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db377b6a",
   "metadata": {},
   "source": [
    "Run from here ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98a9af-8e7a-4971-b638-085c5fde4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shakt\\anaconda3\\envs\\infrapilot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent detected: Deploy Docker on EC2\n",
      "Slot values collected: {'instance_name': 'shakti', 'instance_type': 'ec2.large', 'ami_id': ''}\n",
      "Generated Terraform Configuration:\n",
      " provider \"aws\" {\n",
      "  region = \"us-east-1\"\n",
      "}\n",
      "\n",
      "variable \"instance_name\" {\n",
      "  description = \"Name of the EC2 instance\"\n",
      "  default     = \"shakti\"\n",
      "}\n",
      "\n",
      "variable \"instance_type\" {\n",
      "  description = \"EC2 instance type\"\n",
      "  default     = \"ec2.large\"\n",
      "}\n",
      "\n",
      "variable \"ami_id\" {\n",
      "  description = \"AMI ID for the EC2 instance\"\n",
      "  default     = \"\"\n",
      "}\n",
      "\n",
      "resource \"aws_instance\" \"app_server\" {\n",
      "  ami           = var.ami_id\n",
      "  instance_type = var.instance_type\n",
      "  \n",
      "  tags = {\n",
      "    Name = var.instance_name\n",
      "  }\n",
      "\n",
      "  lifecycle {\n",
      "    ignore_changes = [ami]\n",
      "  }\n",
      "}\n",
      "\n",
      "output \"public_ip\" {\n",
      "  value = aws_instance.app_server.public_ip\n",
      "}\n",
      "**Step 1: Prerequisites**\n",
      "\n",
      "* AWS account with EC2 instance permissions\n",
      "* Docker installed on your local machine\n",
      "* SSH key generated and added to AWS EC2\n",
      "\n",
      "**Step 2: Launch EC2 Instance**\n",
      "\n",
      "* Log in to your AWS Console and navigate to the EC2 dashboard.\n",
      "* Click \"Launch Instance\".\n",
      "\n",
      "**Step 3: Choose AMI**\n",
      "\n",
      "* Select the AMI ID specified in the values provided. If not provided, use the latest Amazon Linux 2 AMI with Docker pre-installed.\n",
      "\n",
      "**Step 4: Choose Instance Type**\n",
      "\n",
      "* Select the instance type specified in the values provided (\"ec2.large\").\n",
      "\n",
      "**Step 5: Instance Details**\n",
      "\n",
      "* Enter a unique instance name (e.g., \"shakti\").\n",
      "\n",
      "**Step 6: Storage**\n",
      "\n",
      "* Adjust the root volume size if needed.\n",
      "\n",
      "**Step 7: Network Settings**\n",
      "\n",
      "* Keep the default security group settings.\n",
      "\n",
      "**Step 8: Review and Launch**\n",
      "\n",
      "* Review the settings and click \"Launch\".\n",
      "* Select the SSH key pair you wish to use.\n",
      "\n",
      "**Step 9: Connect to Instance**\n",
      "\n",
      "* Wait for the instance to launch and become \"running\".\n",
      "* SSH into the instance using the following command:\n",
      "\n",
      "```\n",
      "ssh -i ~/.ssh/{key_name}.pem ec2-user@{instance_public_ip}\n",
      "```\n",
      "\n",
      "where `{key_name}` is the name of your SSH key pair and `{instance_public_ip}` is the public IP address of the EC2 instance.\n",
      "\n",
      "**Step 10: Install Docker**\n",
      "\n",
      "* If Docker is not pre-installed, install it using the following command:\n",
      "\n",
      "```\n",
      "sudo yum install docker\n",
      "```\n",
      "\n",
      "**Step 11: Start Docker**\n",
      "\n",
      "* Start Docker using the command:\n",
      "\n",
      "```\n",
      "sudo systemctl start docker\n",
      "```\n",
      "\n",
      "**Step 12: Dockerize Your Application**\n",
      "\n",
      "* Follow the instructions for dockerizing your application.\n",
      "* Build and push your Docker image to a Docker registry (e.g., Docker Hub).\n",
      "\n",
      "**Step 13: Deploy Docker Container**\n",
      "\n",
      "* Pull your Docker image from the registry:\n",
      "\n",
      "```\n",
      "sudo docker pull {registry_url}/{image_name}\n",
      "```\n",
      "\n",
      "* Run your Docker container:\n",
      "\n",
      "```\n",
      "sudo docker run -d -p {host_port}:{container_port} {image_name}\n",
      "```\n",
      "\n",
      "where `{host_port}` is the port you wish to expose on the host machine, `{container_port}` is the port your container listens on, and `{image_name}` is the name of your Docker image.\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "* Adjust the values for `registry_url`, `image_name`, `host_port`, and `container_port` as per your requirements.\n",
      "* Open the specified host port in the EC2 instance's security group if it is not accessible.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Initialize models\n",
    "GEMINI_API_KEY = \"AIzaSyC2EsHZkvK6GiClAh9J7Bw58pznbSIWt7Y\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Initialize Sentence Transformer\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')  \n",
    "\n",
    "# List of predefined intents\n",
    "intents_list = ['Deploy Docker on EC2', 'Deploy Docker on Kubernetes']\n",
    "\n",
    "# Slot requirements for each intent\n",
    "required_slots = {\n",
    "    \"Deploy Docker on EC2\": [\"instance_name\", \"instance_type\", \"ami_id\"],\n",
    "    \"Deploy Docker on Kubernetes\": [\"cluster_name\", \"node_count\", \"region\"]\n",
    "}\n",
    "\n",
    "def get_intent(user_input, threshold=0.7):\n",
    "    \"\"\"Identify the intent based on user input using sentence transformers.\"\"\"\n",
    "    # Get embeddings\n",
    "    user_embedding = embedding_model.encode([user_input])[0]\n",
    "    intent_embeddings = embedding_model.encode(intents_list)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity([user_embedding], intent_embeddings)\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    most_similar_score = similarities[0][most_similar_idx]\n",
    "    \n",
    "    if most_similar_score >= threshold:\n",
    "        return intents_list[most_similar_idx]\n",
    "    return None\n",
    "\n",
    "def generate_slot_prompts(intent):\n",
    "    \"\"\"Generate prompts to gather slot information.\"\"\"\n",
    "    return required_slots[intent]\n",
    "\n",
    "def collect_slot_values(slot_prompts):\n",
    "    \"\"\"Collect values for each required slot.\"\"\"\n",
    "    slot_values = {}\n",
    "    for prompt in slot_prompts:\n",
    "        user_input = input(f\"{prompt}: \")\n",
    "        slot_values[prompt] = user_input    \n",
    "    return slot_values\n",
    "\n",
    "# Using triple quotes for better template formatting\n",
    "terraform_template = '''provider \"aws\" {{\n",
    "  region = \"us-east-1\"\n",
    "}}\n",
    "\n",
    "variable \"instance_name\" {{\n",
    "  description = \"Name of the EC2 instance\"\n",
    "  default     = \"{instance_name}\"\n",
    "}}\n",
    "\n",
    "variable \"instance_type\" {{\n",
    "  description = \"EC2 instance type\"\n",
    "  default     = \"{instance_type}\"\n",
    "}}\n",
    "\n",
    "variable \"ami_id\" {{\n",
    "  description = \"AMI ID for the EC2 instance\"\n",
    "  default     = \"{ami_id}\"\n",
    "}}\n",
    "\n",
    "resource \"aws_instance\" \"app_server\" {{\n",
    "  ami           = var.ami_id\n",
    "  instance_type = var.instance_type\n",
    "  \n",
    "  tags = {{\n",
    "    Name = var.instance_name\n",
    "  }}\n",
    "\n",
    "  lifecycle {{\n",
    "    ignore_changes = [ami]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "output \"public_ip\" {{\n",
    "  value = aws_instance.app_server.public_ip\n",
    "}}'''\n",
    "\n",
    "def fill_terraform_template(slot_values):\n",
    "    \"\"\"Fill the Terraform template with collected slot values.\"\"\"\n",
    "    return terraform_template.format(\n",
    "        instance_name=slot_values.get(\"instance_name\", \"ec2-instance-template\"),\n",
    "        instance_type=slot_values.get(\"instance_type\", \"t2.micro\"),\n",
    "        ami_id=slot_values.get(\"ami_id\", \"ami-09d56f8956ab235b3\")\n",
    "    )\n",
    "\n",
    "def chatbot(user_input):\n",
    "    \"\"\"Main chatbot flow.\"\"\"\n",
    "    intent = get_intent(user_input)\n",
    "    \n",
    "    if intent:\n",
    "        slot_prompts = generate_slot_prompts(intent)\n",
    "        print(f\"Intent detected: {intent}\")\n",
    "        \n",
    "        slot_values = collect_slot_values(slot_prompts)\n",
    "        print(\"Slot values collected:\", slot_values)\n",
    "        \n",
    "        if intent == \"Deploy Docker on EC2\":\n",
    "            terraform_code = fill_terraform_template(slot_values)\n",
    "            print(\"Generated Terraform Configuration:\\n\", terraform_code)\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            f\"Based on the collected information for {intent}, \"\n",
    "            f\"with values {json.dumps(slot_values)}, \"\n",
    "            \"provide deployment instructions.\"\n",
    "        )\n",
    "        return response.text\n",
    "    \n",
    "    return \"Please specify if you want to deploy Docker on EC2 or Kubernetes.\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"I want to deploy Docker on EC2\"\n",
    "    print(chatbot(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e22fccb-75b0-40bb-b330-54790a153fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shakt\\anaconda3\\envs\\infrapilot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import logging\n",
    "from enum import Enum\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DevOpsIntent(Enum):\n",
    "    DEPLOY_EC2 = \"Deploy Docker on EC2\"\n",
    "    DEPLOY_K8S = \"Deploy Docker on Kubernetes\"\n",
    "    SETUP_CICD = \"Setup CI/CD Pipeline\"\n",
    "    CONFIGURE_MONITORING = \"Configure Monitoring\"\n",
    "    SCALE_INFRASTRUCTURE = \"Scale Infrastructure\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5918a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import logging\n",
    "from enum import Enum\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DevOpsIntent(Enum):\n",
    "    DEPLOY_EC2 = \"Deploy Docker on EC2\"\n",
    "    DEPLOY_K8S = \"Deploy Docker on Kubernetes\"\n",
    "    SETUP_CICD = \"Setup CI/CD Pipeline\"\n",
    "    CONFIGURE_MONITORING = \"Configure Monitoring\"\n",
    "    SCALE_INFRASTRUCTURE = \"Scale Infrastructure\"\n",
    "\n",
    "class InfraPilotChatbot:\n",
    "    def __init__(self, config_path: str = \"config/intents.yaml\"):\n",
    "        load_dotenv()\n",
    "        self.embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        self.load_intent_configs(config_path) \n",
    "        self.conversation_history = []\n",
    "\n",
    "    def load_intent_configs(self, config_path: str):\n",
    "        \"\"\"Load intent configurations from YAML\"\"\"\n",
    "        try:\n",
    "            with open(config_path, 'r') as f:\n",
    "                self.intent_configs = yaml.safe_load(f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load intent configs: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def get_intent(self, user_input: str, threshold: float = 0.7) -> Tuple[Optional[DevOpsIntent], float]:\n",
    "        \"\"\"Enhanced intent detection with confidence score\"\"\"\n",
    "        try:\n",
    "            user_embedding = self.embedding_model.encode([user_input])[0]\n",
    "            intent_texts = [intent.value for intent in DevOpsIntent]\n",
    "            intent_embeddings = self.embedding_model.encode(intent_texts)\n",
    "            \n",
    "            similarities = cosine_similarity([user_embedding], intent_embeddings)\n",
    "            most_similar_idx = np.argmax(similarities)\n",
    "            confidence = similarities[0][most_similar_idx]\n",
    "            \n",
    "            if confidence >= threshold:\n",
    "                return DevOpsIntent(intent_texts[most_similar_idx]), confidence\n",
    "            return None, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Intent detection failed: {e}\")\n",
    "            return None, 0.0\n",
    "            \n",
    "    def collect_slot_values(self, intent: DevOpsIntent) -> Dict[str, str]:\n",
    "        \"\"\"Interactive slot collection\"\"\"\n",
    "        slot_values = {}\n",
    "        intent_config = self.intent_configs.get(intent.name, {})\n",
    "        \n",
    "        for slot_name, slot_config in intent_config.get('required_slots', {}).items():\n",
    "            value = input(f\"{slot_config['description']}: \")\n",
    "            slot_values[slot_name] = value\n",
    "                \n",
    "        return slot_values\n",
    "\n",
    "    def generate_infrastructure_code(self, intent: DevOpsIntent, slot_values: Dict[str, str]) -> str:\n",
    "        \"\"\"Generate infrastructure code based on intent and slots\"\"\"\n",
    "        try:\n",
    "            templates = self.intent_configs.get(intent.name, {}).get('templates', {})\n",
    "            template = templates.get('infrastructure')\n",
    "            \n",
    "            if not template:\n",
    "                raise ValueError(f\"No template found for {intent.name}\")\n",
    "                \n",
    "            return template.format(**slot_values)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Code generation failed: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def process_message(self, user_input: str) -> Dict:\n",
    "        \"\"\"Main message processing pipeline\"\"\"\n",
    "        try:\n",
    "            # Detect intent\n",
    "            intent, confidence = self.get_intent(user_input)\n",
    "            \n",
    "            if not intent:\n",
    "                return {\n",
    "                    \"status\": \"unclear_intent\",\n",
    "                    \"message\": \"I'm not sure what you'd like to do. Could you please be more specific?\"\n",
    "                }\n",
    "                \n",
    "            # Collect necessary information\n",
    "            slot_values = self.collect_slot_values(intent)\n",
    "            \n",
    "            # Generate infrastructure code\n",
    "            infra_code = self.generate_infrastructure_code(intent, slot_values)\n",
    "            \n",
    "            return {\n",
    "                \"status\" : \"success\",\n",
    "                \"intent\" : intent,\n",
    "                \"confidence\" : confidence,\n",
    "                \"infrastructure_code\" : infra_code,\n",
    "                \"configuration\": slot_values\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Message processing failed: {e}\")\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"An error occurred while processing your request.\"\n",
    "            }\n",
    "\n",
    "    def save_conversation(self, filepath: str):\n",
    "        \"\"\"Save conversation history\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(self.conversation_history, f, indent=2)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save conversation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf566048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Welcome to InfraPilot! ===\n",
      "How can I help you with your DevOps tasks?\n",
      "\n",
      "Available commands:\n",
      "- Deploy Docker on EC2\n",
      "- Deploy Docker on Kubernetes\n",
      "- Setup CI/CD Pipeline\n",
      "- Configure Monitoring\n",
      "- Scale Infrastructure\n",
      "\n",
      "Type 'exit' or 'quit' to end the session\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Intent: DevOpsIntent.DEPLOY_EC2 (Confidence: 1.00)\n",
      "\n",
      "Configuration:\n",
      "- instance_name: shakti\n",
      "- instance_type: t2.micro\n",
      "- ami_id: \n",
      "\n",
      "Generated Infrastructure Code:\n",
      "provider \"aws\" {\n",
      "  region = \"us-east-1\"\n",
      "}\n",
      "\n",
      "variable \"instance_name\" {\n",
      "  description = \"Name of the EC2 instance\"\n",
      "  default     = \"shakti\"\n",
      "}\n",
      "\n",
      "variable \"instance_type\" {\n",
      "  description = \"EC2 instance type\"\n",
      "  default     = \"t2.micro\"\n",
      "}\n",
      "\n",
      "variable \"ami_id\" {\n",
      "  description = \"AMI ID for the EC2 instance\"\n",
      "  default     = \"\"\n",
      "}\n",
      "\n",
      "resource \"aws_instance\" \"app_server\" {\n",
      "  ami           = var.ami_id\n",
      "  instance_type = var.instance_type\n",
      "  \n",
      "  tags = {\n",
      "    Name = var.instance_name\n",
      "  }\n",
      "\n",
      "  lifecycle {\n",
      "    ignore_changes = [ami]\n",
      "  }\n",
      "}\n",
      "\n",
      "output \"public_ip\" {\n",
      "  value = aws_instance.app_server.public_ip\n",
      "}\n",
      "\n",
      "\n",
      "Thank you for using InfraPilot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        chatbot = InfraPilotChatbot()\n",
    "        \n",
    "        print(\"\\n=== Welcome to InfraPilot! ===\")\n",
    "        print(\"How can I help you with your DevOps tasks?\")\n",
    "        print(\"\\nAvailable commands:\")\n",
    "        for intent in DevOpsIntent:\n",
    "            print(f\"- {intent.value}\")\n",
    "        print(\"\\nType 'exit' or 'quit' to end the session\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nYou: \").strip()\n",
    "                if user_input.lower() in ['exit', 'quit']:\n",
    "                    print(\"\\nThank you for using InfraPilot. Goodbye!\")\n",
    "                    break\n",
    "                \n",
    "                if not user_input:  # Handle empty input\n",
    "                    print(\"Please enter a command or type 'exit' to quit.\")\n",
    "                    continue\n",
    "                    \n",
    "                response = chatbot.process_message(user_input)\n",
    "                \n",
    "                # Format the response based on status\n",
    "                if response['status'] == 'success':\n",
    "                    print(f\"\\nDetected Intent: {response['intent']} (Confidence: {response['confidence']:.2f})\")\n",
    "                    print(\"\\nConfiguration:\")\n",
    "                    for key, value in response['configuration'].items():\n",
    "                        print(f\"- {key}: {value}\")\n",
    "                    print(\"\\nGenerated Infrastructure Code:\")\n",
    "                    print(response['infrastructure_code'])\n",
    "                else:\n",
    "                    print(f\"\\nInfraPilot: {response['message']}\")\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nOperation cancelled by user. Type 'exit' to quit.\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"\\nAn error occurred: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\nFailed to initialize InfraPilot: {str(e)}\")\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf83469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
