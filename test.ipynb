{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict, Annotated, Sequence, Union, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state schema\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], \"The messages in the conversation\"]\n",
    "    terraform_config: Annotated[Dict, \"Generated Terraform configuration\"]\n",
    "    current_step: Annotated[str, \"Current step in the workflow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyC2EsHZkvK6GiClAh9J7Bw58pznbSIWt7Y'\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "model = ChatVertexAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    try:\n",
    "        # 1. First test if we can initialize the model\n",
    "        logger.debug(\"Initializing model...\")\n",
    "        model = ChatVertexAI(model=\"gemini-1.5-flash\")\n",
    "        logger.debug(\"Model initialized successfully\")\n",
    "\n",
    "        # 2. Create a simple test message\n",
    "        test_message = \"What is 2+2?\"\n",
    "        logger.debug(f\"Sending test message: {test_message}\")\n",
    "\n",
    "        # 3. Create a message and try to get a response\n",
    "        messages = [HumanMessage(content=test_message)]\n",
    "        response = model.invoke(messages)\n",
    "        \n",
    "        logger.debug(f\"Received response: {response.content}\")\n",
    "        print(\"\\nTest Result:\")\n",
    "        print(f\"Input: {test_message}\")\n",
    "        print(f\"Output: {response.content}\")\n",
    "        \n",
    "        return True, \"Model is working properly\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error testing model: {str(e)}\")\n",
    "        return False, f\"Model test failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Initializing model...\n",
      "DEBUG:__main__:Model initialized successfully\n",
      "DEBUG:__main__:Sending test message: What is 2+2?\n",
      "DEBUG:google.auth._default:Checking None for explicit credentials as part of auth process...\n",
      "DEBUG:google.auth._default:Checking Cloud SDK credentials as part of auth process...\n",
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): oauth2.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://oauth2.googleapis.com:443 \"POST /token HTTP/11\" 200 None\n",
      "DEBUG:__main__:Received response: 2 + 2 = 4 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Result:\n",
      "Input: What is 2+2?\n",
      "Output: 2 + 2 = 4 \n",
      "\n",
      "\n",
      "Final Status: ✅ Success\n",
      "Message: Model is working properly\n"
     ]
    }
   ],
   "source": [
    "success, message = test_model()\n",
    "print(f\"\\nFinal Status: {'✅ Success' if success else '❌ Failed'}\")\n",
    "print(f\"Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved prompt with more explicit instructions\n",
    "intent_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"\"\"You are an infrastructure deployment assistant. Analyze the user's request and extract key information for EC2 deployment.\n",
    "    You must return a valid JSON object with exactly these fields:\n",
    "    {\n",
    "        \"instance_type\": \"string (e.g., t2.micro)\",\n",
    "        \"instance_name\": \"string (name for the EC2 instance)\",\n",
    "        \"region\": \"string (AWS region, default to us-east-1 if\" not specified)\"\n",
    "    }\n",
    "    \n",
    "    Only return the JSON object, no other text.\n",
    "    \n",
    "    Example valid response:\n",
    "    {\n",
    "        \"instance_type\": \"t2.micro\",\n",
    "        \"instance_name\": \"web-server\",\n",
    "        \"region\": \"us-east-1\"\n",
    "    }\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the terraform template as a raw string\n",
    "TERRAFORM_TEMPLATE = '''provider \"aws\" {\n",
    "  region = \"{region}\"\n",
    "}\n",
    "\n",
    "variable \"instance_name\" {\n",
    "  description = \"Name of the EC2 instance\"\n",
    "  default = \"{instance_name}\"\n",
    "}\n",
    "\n",
    "variable \"instance_type\" {\n",
    "  description = \"EC2 instance type\"\n",
    "  default = \"{instance_type}\"\n",
    "}\n",
    "\n",
    "variable \"ami_id\" {\n",
    "  description = \"AMI ID for the EC2 instance\"\n",
    "  default = \"ami-09d56f8956ab235b3\"\n",
    "}\n",
    "\n",
    "resource \"aws_instance\" \"app_server\" {\n",
    "  ami = var.ami_id\n",
    "  instance_type = var.instance_type\n",
    "  tags = {\n",
    "    Name = var.instance_name\n",
    "  }\n",
    "  lifecycle {\n",
    "    ignore_changes = [ami]\n",
    "  }\n",
    "}\n",
    "\n",
    "output \"public_ip\" {\n",
    "  value = aws_instance.app_server.public_ip\n",
    "}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_params(params: Dict) -> bool:\n",
    "    \"\"\"Validate the extracted parameters.\"\"\"\n",
    "    required_fields = [\"instance_type\", \"instance_name\", \"region\"]\n",
    "    \n",
    "    # Check if all required fields are present\n",
    "    if not all(field in params for field in required_fields):\n",
    "        logger.error(f\"Missing required fields. Got: {params.keys()}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if values are non-empty strings\n",
    "    if not all(isinstance(params[field], str) and params[field].strip() for field in required_fields):\n",
    "        logger.error(f\"Invalid value types or empty strings: {params}\")\n",
    "        return False\n",
    "    \n",
    "    # Validate instance type format (optional)\n",
    "    if not re.match(r'^[a-z]+[0-9]+\\.[a-z]+$', params['instance_type']):\n",
    "        logger.error(f\"Invalid instance type format: {params['instance_type']}\")\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_intent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Analyze user intent and extract deployment parameters.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    try:\n",
    "        # Get parameters from LLM\n",
    "        logger.debug(\"Sending request to LLM\")\n",
    "        response = model.invoke(intent_prompt.format_messages(messages=messages))\n",
    "        logger.debug(f\"LLM Response: {response.content}\")\n",
    "        \n",
    "        # Try to parse JSON response\n",
    "        params = json.loads(response.content)\n",
    "        logger.debug(f\"Parsed parameters: {params}\")\n",
    "        \n",
    "        # Validate parameters\n",
    "        if not validate_params(params):\n",
    "            raise ValueError(\"Invalid parameters structure\")\n",
    "        \n",
    "        # Update state\n",
    "        new_state = state.copy()\n",
    "        new_state[\"terraform_config\"] = params\n",
    "        new_state[\"messages\"] = list(state[\"messages\"])\n",
    "        new_state[\"messages\"].append(AIMessage(\n",
    "            content=f\"I'll help you create an EC2 instance with:\\n\"\n",
    "                   f\"- Instance Type: {params['instance_type']}\\n\"\n",
    "                   f\"- Instance Name: {params['instance_name']}\\n\"\n",
    "                   f\"- Region: {params['region']}\"\n",
    "        ))\n",
    "        new_state[\"current_step\"] = \"generate_terraform\"\n",
    "        \n",
    "        logger.debug(\"Successfully updated state with parameters\")\n",
    "        return new_state\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"JSON parsing error: {e}\")\n",
    "        logger.error(f\"Raw response: {response.content if 'response' in locals() else 'No response'}\")\n",
    "        new_state = state.copy()\n",
    "        new_state[\"messages\"] = list(state[\"messages\"])\n",
    "        new_state[\"messages\"].append(AIMessage(\n",
    "            content=\"I couldn't parse the deployment parameters. Please provide more specific requirements.\"\n",
    "        ))\n",
    "        new_state[\"current_step\"] = \"end\"\n",
    "        return new_state\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in analyze_intent: {str(e)}\")\n",
    "        new_state = state.copy()\n",
    "        new_state[\"messages\"] = list(state[\"messages\"])\n",
    "        new_state[\"messages\"].append(AIMessage(\n",
    "            content=f\"An error occurred: {str(e)}. Please try again with more specific requirements.\"\n",
    "        ))\n",
    "        new_state[\"current_step\"] = \"end\"\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_terraform(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate Terraform configuration based on extracted parameters.\"\"\"\n",
    "    try:\n",
    "        logger.debug(\"Generating Terraform configuration\")\n",
    "        config = state[\"terraform_config\"]\n",
    "        \n",
    "        # Generate Terraform configuration by replacing placeholders\n",
    "        terraform_code = TERRAFORM_TEMPLATE.format(\n",
    "            region=config['region'],\n",
    "            instance_name=config['instance_name'],\n",
    "            instance_type=config['instance_type']\n",
    "        )\n",
    "        \n",
    "        logger.debug(\"Successfully generated Terraform code\")\n",
    "        \n",
    "        # Create new state\n",
    "        new_state = state.copy()\n",
    "        new_state[\"terraform_config\"] = dict(state[\"terraform_config\"])\n",
    "        new_state[\"terraform_config\"][\"terraform_code\"] = terraform_code\n",
    "        new_state[\"messages\"] = list(state[\"messages\"])\n",
    "        new_state[\"messages\"].append(AIMessage(\n",
    "            content=f\"Here's your Terraform configuration:\\n\\n```hcl\\n{terraform_code}\\n```\"\n",
    "        ))\n",
    "        new_state[\"current_step\"] = \"end\"\n",
    "        \n",
    "        return new_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate_terraform: {str(e)}\")\n",
    "        new_state = state.copy()\n",
    "        new_state[\"messages\"] = list(state[\"messages\"])\n",
    "        new_state[\"messages\"].append(AIMessage(\n",
    "            content=f\"Error generating Terraform configuration: {str(e)}\"\n",
    "        ))\n",
    "        new_state[\"current_step\"] = \"end\"\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"analyze_intent\", analyze_intent)\n",
    "workflow.add_node(\"generate_terraform\", generate_terraform)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"analyze_intent\", \"generate_terraform\")\n",
    "workflow.add_edge(\"generate_terraform\", END)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"analyze_intent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_ec2_request(user_message: str) -> str:\n",
    "    \"\"\"Handle EC2 creation requests and return Terraform configuration.\"\"\"\n",
    "    logger.info(f\"Processing request: {user_message}\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user_message)],\n",
    "        \"terraform_config\": {},\n",
    "        \"current_step\": \"analyze_intent\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Execute the workflow\n",
    "        final_state = app.invoke(initial_state)\n",
    "        \n",
    "        # Check if terraform configuration was generated\n",
    "        if \"terraform_config\" in final_state and \"terraform_code\" in final_state[\"terraform_config\"]:\n",
    "            logger.info(\"Successfully generated Terraform configuration\")\n",
    "            return final_state[\"terraform_config\"][\"terraform_code\"]\n",
    "        \n",
    "        # Return error message if no configuration was generated\n",
    "        logger.error(\"Failed to generate Terraform configuration\")\n",
    "        return \"Failed to generate configuration. Please try again with more specific requirements.\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in handle_ec2_request: {str(e)}\")\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing request: Create an EC2 instance with t2.micro instance type named 'web-server' in us-east-1\n",
      "DEBUG:__main__:Sending request to LLM\n",
      "ERROR:__main__:Error in analyze_intent: '\\n        \"instance_type\"'\n",
      "DEBUG:__main__:Generating Terraform configuration\n",
      "ERROR:__main__:Error in generate_terraform: 'region'\n",
      "ERROR:__main__:Failed to generate Terraform configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate configuration. Please try again with more specific requirements.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_request = \"Create an EC2 instance with t2.micro instance type named 'web-server' in us-east-1\"\n",
    "    result = handle_ec2_request(user_request)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sending Messages ===\n",
      "System: You are a helpful assistant that returns EC2 configuration parameters in JSON format.\n",
      "    Example output:\n",
      "    {\n",
      "        \"instance_type\": \"t2.micro\",\n",
      "        \"instance_name\": \"web-server\",\n",
      "        \"region\": \"us-east-1\"\n",
      "    }\n",
      "User: Create an EC2 instance with t2.large instance type named 'web-server' in us-west-1\n",
      "\n",
      "=== Raw Response ===\n",
      "```json\n",
      "{\n",
      "  \"instance_type\": \"t2.large\",\n",
      "  \"instance_name\": \"web-server\",\n",
      "  \"region\": \"us-west-1\"\n",
      "}\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"\"\"Extract EC2 deployment parameters from the request.\n",
    "    Return only a JSON object like this:\n",
    "    {\n",
    "        \"instance_type\": \"t2.micro\",\n",
    "        \"instance_name\": \"web-server\",\n",
    "        \"region\": \"us-east-1\"\n",
    "    }\"\"\")\n",
    "])\n",
    "\n",
    "def test_model_response():\n",
    "    \"\"\"Test the most basic interaction with the model\"\"\"\n",
    "    \n",
    "    # System message to enforce JSON format\n",
    "    system_msg = SystemMessage(content=\"\"\"You are a helpful assistant that returns EC2 configuration parameters in JSON format.\n",
    "    Example output:\n",
    "    {\n",
    "        \"instance_type\": \"t2.micro\",\n",
    "        \"instance_name\": \"web-server\",\n",
    "        \"region\": \"us-east-1\"\n",
    "    }\"\"\")\n",
    "    \n",
    "    # User message\n",
    "    user_msg = HumanMessage(content=\"Create an EC2 instance with t2.large instance type named 'web-server' in us-west-1\")\n",
    "    \n",
    "    # Send messages\n",
    "    print(\"\\n=== Sending Messages ===\")\n",
    "    print(f\"System: {system_msg.content}\")\n",
    "    print(f\"User: {user_msg.content}\")\n",
    "    \n",
    "    # Get response\n",
    "    print(\"\\n=== Raw Response ===\")\n",
    "    response = model.invoke([system_msg, user_msg])\n",
    "    print(response.content)\n",
    "\n",
    "test_model_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
